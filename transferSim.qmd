---
title: "Nonpara clustering"
date: 2023-10-19
format: 
  pdf:
    toc: true
execute: 
  echo: true
  warning: false
  message: false
  error: false
---



# Simulation
```{python setup}
#| include: false
#| output: false
#| message: false

from ctypes import CDLL 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from xarray import DataArray
import pandas_plink as pdplink
import os

try : 
  os.chdir("../../Stat_gen/tools/MASH")
  from Simulate.simulation_helpers.Sim_generator import pheno_simulator
  from Simulate.summarizers.genotype_viz import plotClusters
  # from Simulate.summarizers.genotype_viz import plotClusters
  os.chdir("../../../Integrative/prsPPMx/")
except NameError :
  print("Already loaded appropriate modules")
```
- $\#SNPs = $ `python print(nSNPs)` $< 2000$ [is typical](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6931355/)
- $\#Subjects = $ `python print(nsubjects)`

```{python}
#| message: false

nSNPs = 1000
nsubjects = 500
nclusts = 1
nphenos = 2
shared = 0.5
prop_causal = [0.25, 0.25]
theta_alleles = [0.95, 0.25]
h2Hom =0.8
# Add this for transfer learning 
h2Het = [0.1, 0.1]

rng = np.random.default_rng(12)
nclusts = 2 


sim = pheno_simulator(nsubjects = nsubjects, nSNPs = nSNPs)
sim.sim_sites()
sim.sim_pops(nclusts = nclusts, theta_alleles = theta_alleles, shared = shared)
sim.sim_genos()
sim.sim_pheno(h2Hom =h2Hom, h2Het = h2Het, nphenos = nphenos, prop_causal = prop_causal, alpha =-1)
sim.save_plink("test2")


sim.fitGWAS(prefix = "test2")
```


```{python}


# Subtract the mean from every column starting with Y and store them in the dataframe
sim.df.iloc[:,30:(30+nphenos)] = sim.df.filter(regex='^Y') - sim.df.filter(regex= "^Y").mean()

# Get row numbers where subject_ancestries is 0
anc0 = sim.df[sim.df["subj_ancestries"] == 0].index

# for each columns starting with letter Y, run a simple linear regression with the 
GWASBetas = np.zeros(shape = (sim.genotypes.shape[1], sim.df.filter(regex="^Y").shape[1]))
pvals = np.zeros(shape = (sim.genotypes.shape[1], sim.df.filter(regex="^Y").shape[1]))
genos = pd.DataFrame(sm.add_constant(sim.genotypes))

for j in range(sim.df.filter(regex="^Y").shape[1]):
    for i in range(sim.genotypes.shape[1]-1):
    mod = sm.OLS(sim.df.iloc[anc0,:]["Y" + str(j)], sm.add_constant(genos.iloc[anc0,:][[0,i+1]])).fit()
        GWASBetas[i,j] = mod.params[i+1]
        pvals[i] = mod.pvalues[i+1]
        # find the 75% of pvals
    p75 = np.percentile(pvals[i], 75)
    # Set all values below the 75th percentile to 0
    GWASBetas[i,j][pvals[i] < p75] = 0
        
    # 
    # Standardize the sim.genotypes
    Z = (sim.genotypes - sim.genotypes.mean(axis = 0)) / sim.genotypes.std(axis = 0) 
    sim.df[f"PRS{j}"] = np.matmul(Z, GWASBetas[:,j])

np.save("genos2Anc.npy", sim.genotypes)

# Save GWAS results
np.save("gwas2Anc.npy", GWASBetas)

# Create confounding variable that is related to risk subgorup

# Save dataframe
sim.df.to_csv("data2Anc.csv", index = False)

# SNP_props = pd.DataFrame({"Shared" : [0, 0, 1, 1],
#               "Causal" : [0, 1, 0, 1],
#               "N" : np.array([(1 - shared) * (1 - prop_causal[0]),
#                               (1 - shared) * prop_causal[0],
#                               shared * (1 - prop_causal[1]),
#                               shared * (prop_causal[1])]) * nSNPs})
# ax = sns.barplot(data= SNP_props, x = "Shared", y = "N", hue = "Causal", )
# ax.set(yscale = "log") # plotClusters(sim)
# plt.show()

# Grab sim.df where subj_ancestries == 0
test = sim.df[sim.df["subj_ancestries"] == 0]

sns.scatterplot(x = "PRS0", y = "Y0", data = test)
sns.scatterplot(x = "PRS1", y = "Y1", data = test)

plt.show()
```


```{python}
plotClusters(sim)
```


```{python}
# make two subplots
# one for phenotype y0 and another for phenotype y1
p1 = sns.jointplot(x= "PRS0" , y ="Y0", data = sim.df)
p2 = sns.jointplot(x= "PRS1" , y ="Y1", data = sim.df)

plt.show()
```




# Data Generating mechanism

Trying to detect risk subgroups while simultatenously compute a PRS.

$$
  Y = X_cβ_c + X_Gβ_G + X_Rβ_R + ϵ
$$

Implies

$$
  Y = X_cβ_c + PRSβ_{PRS} + PCβ_{PC} + ϵ
$$

Where $X$ is the confounding variable, $X_G$ is the genetic variable, $β$ is the effect of the confounding variable, $β_G$ is the effect of the genetic variable, $β_{PRS}$ is the effect of the PRS, $β_{PC}$ is the effect of the principal components, $X_R$ is the risk group, $β_R$ is the risk group effect, and $ϵ$ is the error term. Additionally, $X_c$ depends on $X_R$

$$
  p(X_c|X_R) = \begin{cases} 
  0.75 & \text{if } X_R = 1 \\
  0.25 & \text{if } X_R = 0
\end{cases}
$$


# PPMx fits
```{r setupR}
#| include: false
library(ppmSuite)
library(tidyverse)
library(ggfortify)
library(gt)
library(patchwork)
library(gtsummary)


ppmxsummary <- function(mod, df, ...) {
  df$predicted <- apply(mod$fitted.values, 2, mean)
  labelings <- t(mod$Si)
  df$label <- as.data.frame(sapply(1:max(mod$Si), function(x) rowMeans(labelings ==x)),
                            col.names = c("l1", "l2", "l3"))  %>%
             mutate(label = max.col(., ties.method = "first")) %>%
             pull(label) %>%
             as.factor()
  g <- df %>%
    ggplot(aes(!!!ensyms(...))) +
    geom_point() +
    geom_point(aes(y = predicted), color = "red") 
  print(g)
 
  table(df[c("label", "subgroup", "subj_ancestries")])
}

meanModel = 1
M=1e-30
similarity_function = 1
draws = 2000
burn = 500
thin = 10

# Load datafraem
df <- read_csv("data2Anc.csv")  %>%
  mutate(Y0 = (Y0 - mean(Y0))/ sd(Y0),
         Y1 = (Y1 - mean(Y1)) / sd(Y1),
         PRS0 = (PRS0 - mean(PRS0)) / sd(PRS0),
         PRS1 = (PRS1 - mean(PRS1)) / sd(PRS1), 
         pc_1 = (pc_1 - mean(pc_1)) / sd(pc_1),
         Y1_PC = lm(Y1 ~ pc_1, data= .)$resid,
         PRS1_PC = lm(PRS1 ~ pc_1, data= .)$resid,
         subgroup = 1
         )
```

## Fully separable
```{r}
# Fully separable: no confounding - 
m1 = gaussian_ppmx(y = df$Y1, X = df[c("PRS1", "pc_1")], meanModel = meanModel, M = M, similarity_function = similarity_function, draws = draws, burn = burn, thin = thin)
ppmxsummary(m1, df, x ="PRS1", y= "Y1")
```


## PC residualized
Residualize out confounding affect
```{r}
m2 = gaussian_ppmx(y = df$Y1_PC, X = df[c("PRS1_PC")], meanModel = meanModel, M = M, similarity_function = similarity_function, draws = draws, burn = burn, thin = thin)
ppmxsummary(m2, df, x ="PRS1_PC", y= "Y1_PC")
```
Doesn't detect subtypes

